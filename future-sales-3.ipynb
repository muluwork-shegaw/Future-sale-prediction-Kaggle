{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "future-sales-3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCW5BJHx0bdE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "61b64b3d-333b-4a69-c787-95e514478f1b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\",force_remount=True)\n",
        "# %cd \"drive/My Drive/\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibZhGpMc0X-S",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The Future Sales competition is the final assesment in the 'How to win a Data Science' course in the Advanced Machine Learning specialisation from HSE University, Moscow. The aim is to predict the monthly sales of items in specific shops, given historical data. The sale counts are clipped between 0 and 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lmw-_F6o0X-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas.util.testing as tm\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WscF3_wD0X-h",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqG7c91b87K0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqGAn8Xv87nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "outputId": "99e9e152-6b98-4a88-8be0-e4aa10f5dd07"
      },
      "source": [
        "%cd \"gdrive/My Drive/Kaggle\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-19-aa40adb06915>\", line 1, in <module>\n",
            "    get_ipython().magic('cd \"gdrive/My Drive/Kaggle\"')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2160, in magic\n",
            "    return self.run_line_magic(magic_name, magic_arg_s)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2081, in run_line_magic\n",
            "    result = fn(*args,**kwargs)\n",
            "  File \"<decorator-gen-91>\", line 2, in cd\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
            "    call = lambda f, *a, **k: f(*a, **k)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magics/osm.py\", line 288, in cd\n",
            "    oldcwd = py3compat.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfAdLIUU7rpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "#  !mkdir -p ~/.kaggle\n",
        "\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# !kaggle competitions download -c rossmann-store-sales\n",
        "\n",
        "# from zipfile import ZipFile\n",
        "# file_name = \"test.csv.zip\"\n",
        "# file_name = \"train.csv.zip\"\n",
        "\n",
        "\n",
        "# with ZipFile(file_name,\"r\") as zip:\n",
        "#   zip.extractall()\n",
        "#   print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O1MZRFKf0X-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "a9952ae1-2916-4f26-f6ca-e026f170b0f7"
      },
      "source": [
        "# load data\n",
        "items=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\n",
        "shops=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\n",
        "cats=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\n",
        "train=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\n",
        "test=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-26c1d3979ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mshops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /kaggle/input/competitive-data-science-predict-future-sales/items.csv does not exist: '/kaggle/input/competitive-data-science-predict-future-sales/items.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuJhFIxp0X-q",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data Cleaning\n",
        "\n",
        "We'll remove outliers, clean up some of the raw data and add some new variables to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX-HvFJM0X-q",
        "colab_type": "text"
      },
      "source": [
        "# Remove outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qWMXho5L0X-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.xlim(-100, 3000)\n",
        "flierprops = dict(marker='o', markerfacecolor='purple', markersize=6,\n",
        "                  linestyle='none', markeredgecolor='black')\n",
        "sns.boxplot(x=train.item_cnt_day, flierprops=flierprops)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.xlim(train.item_price.min(), train.item_price.max()*1.1)\n",
        "sns.boxplot(x=train.item_price, flierprops=flierprops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3LJ2THg0X-v",
        "colab_type": "text"
      },
      "source": [
        "We'll remove the obvious outliers in the dataset - the items that sold more than 1000 in one day and the item with price greater than 300,000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xtqjyE970X-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[(train.item_price < 300000 )& (train.item_cnt_day < 1000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XALZx6kx0X-0",
        "colab_type": "text"
      },
      "source": [
        "Remove any rows from train where item price is negative - these could be refunds. Also make zero and item_cnt_day values less than one, to remove negative values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jt6vND1W0X-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[train.item_price > 0].reset_index(drop = True)\n",
        "train.loc[train.item_cnt_day < 1, \"item_cnt_day\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KXtPXnz0X-4",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning Shop Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwO1PNm40X-4",
        "colab_type": "text"
      },
      "source": [
        "Several of the shops look like duplicates of each other. This could be down to shops re-opening or possibly moving store location on the same street or shopping centre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rUVSGo6v0X-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Якутск Орджоникидзе, 56\n",
        "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
        "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
        "# Якутск ТЦ \"Центральный\"\n",
        "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
        "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
        "# Жуковский ул. Чкалова 39м²\n",
        "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
        "test.loc[test.shop_id == 10, 'shop_id'] = 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRRgbakg0X-9",
        "colab_type": "text"
      },
      "source": [
        "Clean up some shop names and add 'city' and 'category' to shops df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h6RMPTSa0X--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shops.loc[ shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"',\"shop_name\" ] = 'СергиевПосад ТЦ \"7Я\"'\n",
        "shops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] )\n",
        "shops[\"category\"] = shops.shop_name.str.split(\" \").map( lambda x: x[1] )\n",
        "shops.loc[shops.city == \"!Якутск\", \"city\"] = \"Якутск\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cPHs-i00X_C",
        "colab_type": "text"
      },
      "source": [
        "Only keep shop category if there are 5 or more shops of that category, the rest are grouped as \"other\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oVPt_cqM0X_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category = []\n",
        "for cat in shops.category.unique():\n",
        "    if len(shops[shops.category == cat]) >= 5:\n",
        "        category.append(cat)\n",
        "shops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w_WEgEvQ0X_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "shops[\"shop_category\"] = LabelEncoder().fit_transform( shops.category )\n",
        "shops[\"shop_city\"] = LabelEncoder().fit_transform( shops.city )\n",
        "shops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPx43koh0X_J",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning Item Category Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8-kv9Amv0X_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cats[\"type_code\"] = cats.item_category_name.apply( lambda x: x.split(\" \")[0] ).astype(str)\n",
        "cats.loc[ (cats.type_code == \"Игровые\")| (cats.type_code == \"Аксессуары\"), \"category\" ] = \"Игры\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3ej8XsIG0X_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category = []\n",
        "for cat in cats.type_code.unique():\n",
        "    if len(cats[cats.type_code == cat]) >= 5: \n",
        "        category.append( cat )\n",
        "cats.type_code = cats.type_code.apply(lambda x: x if (x in category) else \"etc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KO0EaHi80X_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cats.type_code = LabelEncoder().fit_transform(cats.type_code)\n",
        "cats[\"split\"] = cats.item_category_name.apply(lambda x: x.split(\"-\"))\n",
        "cats[\"subtype\"] = cats.split.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
        "cats[\"subtype_code\"] = LabelEncoder().fit_transform( cats[\"subtype\"] )\n",
        "cats = cats[[\"item_category_id\", \"subtype_code\", \"type_code\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wem0eEXL0X_W",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning Item Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ohrsw56B0X_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def name_correction(x):\n",
        "    x = x.lower() # all letters lower case\n",
        "    x = x.partition('[')[0] # partition by square brackets\n",
        "    x = x.partition('(')[0] # partition by curly brackets\n",
        "    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x) # remove special characters\n",
        "    x = x.replace('  ', ' ') # replace double spaces with single spaces\n",
        "    x = x.strip() # remove leading and trailing white space\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbrCBLdk0X_a",
        "colab_type": "text"
      },
      "source": [
        "Clean item names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fImz4CAZ0X_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split item names by first bracket\n",
        "items[\"name1\"], items[\"name2\"] = items.item_name.str.split(\"[\", 1).str\n",
        "items[\"name1\"], items[\"name3\"] = items.item_name.str.split(\"(\", 1).str\n",
        "\n",
        "# replace special characters and turn to lower case\n",
        "items[\"name2\"] = items.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
        "items[\"name3\"] = items.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
        "\n",
        "# fill nulls with '0'\n",
        "items = items.fillna('0')\n",
        "\n",
        "items[\"item_name\"] = items[\"item_name\"].apply(lambda x: name_correction(x))\n",
        "\n",
        "# return all characters except the last if name 2 is not \"0\" - the closing bracket\n",
        "items.name2 = items.name2.apply( lambda x: x[:-1] if x !=\"0\" else \"0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wPv36To0X_d",
        "colab_type": "text"
      },
      "source": [
        "Clean item type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iIgzB7_Y0X_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "items[\"type\"] = items.name2.apply(lambda x: x[0:8] if x.split(\" \")[0] == \"xbox\" else x.split(\" \")[0] )\n",
        "items.loc[(items.type == \"x360\") | (items.type == \"xbox360\") | (items.type == \"xbox 360\") ,\"type\"] = \"xbox 360\"\n",
        "items.loc[ items.type == \"\", \"type\"] = \"mac\"\n",
        "items.type = items.type.apply( lambda x: x.replace(\" \", \"\") )\n",
        "items.loc[ (items.type == 'pc' )| (items.type == 'pс') | (items.type == \"pc\"), \"type\" ] = \"pc\"\n",
        "items.loc[ items.type == 'рs3' , \"type\"] = \"ps3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cg2w1iIK0X_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "group_sum = items.groupby([\"type\"]).agg({\"item_id\": \"count\"})\n",
        "group_sum = group_sum.reset_index()\n",
        "drop_cols = []\n",
        "for cat in group_sum.type.unique():\n",
        "    if group_sum.loc[(group_sum.type == cat), \"item_id\"].values[0] <40:\n",
        "        drop_cols.append(cat)\n",
        "items.name2 = items.name2.apply( lambda x: \"other\" if (x in drop_cols) else x )\n",
        "items = items.drop([\"type\"], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "c-izqtGS0X_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "items.name2 = LabelEncoder().fit_transform(items.name2)\n",
        "items.name3 = LabelEncoder().fit_transform(items.name3)\n",
        "\n",
        "items.drop([\"item_name\", \"name1\"],axis = 1, inplace= True)\n",
        "items.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg8oaors0X_n",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Create a matrix df with every combination of month, shop and item in order of increasing month. Item_cnt_day is summed into an item_cnt_month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "28iMoGev0X_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import product\n",
        "import time\n",
        "ts = time.time()\n",
        "matrix = []\n",
        "cols  = [\"date_block_num\", \"shop_id\", \"item_id\"]\n",
        "for i in range(34):\n",
        "    sales = train[train.date_block_num == i]\n",
        "    matrix.append( np.array(list( product( [i], sales.shop_id.unique(), sales.item_id.unique() ) ), dtype = np.int16) )\n",
        "\n",
        "matrix = pd.DataFrame( np.vstack(matrix), columns = cols )\n",
        "matrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8)\n",
        "matrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8)\n",
        "matrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16)\n",
        "matrix.sort_values( cols, inplace = True )\n",
        "time.time()- ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U97n7Q-50X_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add revenue to train df\n",
        "train[\"revenue\"] = train[\"item_cnt_day\"] * train[\"item_price\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_Dv7r2-J0X_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = train.groupby( [\"date_block_num\", \"shop_id\", \"item_id\"] ).agg( {\"item_cnt_day\": [\"sum\"]} )\n",
        "group.columns = [\"item_cnt_month\"]\n",
        "group.reset_index( inplace = True)\n",
        "matrix = pd.merge( matrix, group, on = cols, how = \"left\" )\n",
        "matrix[\"item_cnt_month\"] = matrix[\"item_cnt_month\"].fillna(0).astype(np.float16)\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNuDEuBz0X_u",
        "colab_type": "text"
      },
      "source": [
        "Create a test set for month 34."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xjoX70560X_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[\"date_block_num\"] = 34\n",
        "test[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\n",
        "test[\"shop_id\"] = test.shop_id.astype(np.int8)\n",
        "test[\"item_id\"] = test.item_id.astype(np.int16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqQDuGfa0X_x",
        "colab_type": "text"
      },
      "source": [
        "Concatenate train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sZ_d2BaI0X_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "\n",
        "matrix = pd.concat([matrix, test.drop([\"ID\"],axis = 1)], ignore_index=True, sort=False, keys=cols)\n",
        "matrix.fillna( 0, inplace = True )\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa9AhWMa0X_2",
        "colab_type": "text"
      },
      "source": [
        "Add shop, items and categories data onto matrix df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "oz816hYF0X_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "matrix = pd.merge( matrix, shops, on = [\"shop_id\"], how = \"left\" )\n",
        "matrix = pd.merge(matrix, items, on = [\"item_id\"], how = \"left\")\n",
        "matrix = pd.merge( matrix, cats, on = [\"item_category_id\"], how = \"left\" )\n",
        "matrix[\"shop_city\"] = matrix[\"shop_city\"].astype(np.int8)\n",
        "matrix[\"shop_category\"] = matrix[\"shop_category\"].astype(np.int8)\n",
        "matrix[\"item_category_id\"] = matrix[\"item_category_id\"].astype(np.int8)\n",
        "matrix[\"subtype_code\"] = matrix[\"subtype_code\"].astype(np.int8)\n",
        "matrix[\"name2\"] = matrix[\"name2\"].astype(np.int8)\n",
        "matrix[\"name3\"] = matrix[\"name3\"].astype(np.int16)\n",
        "matrix[\"type_code\"] = matrix[\"type_code\"].astype(np.int8)\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5rpx4I50X_6",
        "colab_type": "text"
      },
      "source": [
        "Feature Engineering\n",
        "\n",
        "* Add lag features to matrix df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "p5NWLQk40X_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a lag feature function\n",
        "def lag_feature( df,lags, cols ):\n",
        "    for col in cols:\n",
        "        print(col)\n",
        "        tmp = df[[\"date_block_num\", \"shop_id\",\"item_id\",col ]]\n",
        "        for i in lags:\n",
        "            shifted = tmp.copy()\n",
        "            shifted.columns = [\"date_block_num\", \"shop_id\", \"item_id\", col + \"_lag_\"+str(i)]\n",
        "            shifted.date_block_num = shifted.date_block_num + i\n",
        "            df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW26EQWL0X_9",
        "colab_type": "text"
      },
      "source": [
        "Add item_cnt_month lag features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yHIwB9Ox0X_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "matrix = lag_feature( matrix, [1,2,3], [\"item_cnt_month\"] )\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SaDIo0H0YAA",
        "colab_type": "text"
      },
      "source": [
        "Add the previous month's average item_cnt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2oGBto7a0YAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = matrix.groupby( [\"date_block_num\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n",
        "group.columns = [\"date_avg_item_cnt\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on = [\"date_block_num\"], how = \"left\")\n",
        "matrix.date_avg_item_cnt = matrix[\"date_avg_item_cnt\"].astype(np.float16)\n",
        "matrix = lag_feature( matrix, [1], [\"date_avg_item_cnt\"] )\n",
        "matrix.drop( [\"date_avg_item_cnt\"], axis = 1, inplace = True )\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCy2-obf0YAD",
        "colab_type": "text"
      },
      "source": [
        "Add lag values of item_cnt_month for month / item_id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YiT0FCo20YAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
        "group.columns = [ 'date_item_avg_item_cnt' ]\n",
        "group.reset_index(inplace=True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
        "matrix.date_item_avg_item_cnt = matrix['date_item_avg_item_cnt'].astype(np.float16)\n",
        "matrix = lag_feature(matrix, [1,2,3], ['date_item_avg_item_cnt'])\n",
        "matrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWWcraRs0YAJ",
        "colab_type": "text"
      },
      "source": [
        "Add lag values for item_cnt_month for every month / shop combination."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JDL7WW0R0YAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = matrix.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n",
        "group.columns = [\"date_shop_avg_item_cnt\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\"], how = \"left\")\n",
        "matrix.date_avg_item_cnt = matrix[\"date_shop_avg_item_cnt\"].astype(np.float16)\n",
        "matrix = lag_feature( matrix, [1,2,3], [\"date_shop_avg_item_cnt\"] )\n",
        "matrix.drop( [\"date_shop_avg_item_cnt\"], axis = 1, inplace = True )\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB2RZHEE0YAL",
        "colab_type": "text"
      },
      "source": [
        "Add lag values for item_cnt_month for month/shop/item."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MkLnoC4n0YAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = matrix.groupby( [\"date_block_num\",\"shop_id\",\"item_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n",
        "group.columns = [\"date_shop_item_avg_item_cnt\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\",\"item_id\"], how = \"left\")\n",
        "matrix.date_avg_item_cnt = matrix[\"date_shop_item_avg_item_cnt\"].astype(np.float16)\n",
        "matrix = lag_feature( matrix, [1,2,3], [\"date_shop_item_avg_item_cnt\"] )\n",
        "matrix.drop( [\"date_shop_item_avg_item_cnt\"], axis = 1, inplace = True )\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyRfnN0YAQ",
        "colab_type": "text"
      },
      "source": [
        "Add lag values for item_cnt_month for month/shop/item subtype."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VWj0n8op0YAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
        "group.columns = ['date_shop_subtype_avg_item_cnt']\n",
        "group.reset_index(inplace=True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\n",
        "matrix.date_shop_subtype_avg_item_cnt = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\n",
        "matrix = lag_feature(matrix, [1], ['date_shop_subtype_avg_item_cnt'])\n",
        "matrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Gchvd60YAT",
        "colab_type": "text"
      },
      "source": [
        "Add lag values for item_cnt_month for month/city."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bS4h44do0YAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = matrix.groupby(['date_block_num', 'shop_city']).agg({'item_cnt_month': ['mean']})\n",
        "group.columns = ['date_city_avg_item_cnt']\n",
        "group.reset_index(inplace=True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on=['date_block_num', \"shop_city\"], how='left')\n",
        "matrix.date_city_avg_item_cnt = matrix['date_city_avg_item_cnt'].astype(np.float16)\n",
        "matrix = lag_feature(matrix, [1], ['date_city_avg_item_cnt'])\n",
        "matrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziv71O6w0YAW",
        "colab_type": "text"
      },
      "source": [
        "Add lag values for item_cnt_month for month/city/item."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m7hKwuu90YAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = matrix.groupby(['date_block_num', 'item_id', 'shop_city']).agg({'item_cnt_month': ['mean']})\n",
        "group.columns = [ 'date_item_city_avg_item_cnt' ]\n",
        "group.reset_index(inplace=True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_city'], how='left')\n",
        "matrix.date_item_city_avg_item_cnt = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\n",
        "matrix = lag_feature(matrix, [1], ['date_item_city_avg_item_cnt'])\n",
        "matrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IuWOHUc0YAZ",
        "colab_type": "text"
      },
      "source": [
        "* Add average item price on to matix df. \n",
        "* Add lag values of item price per month.\n",
        "* Add delta price values - how current month average pirce relates to global average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rHMVz80m0YAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = train.groupby( [\"item_id\"] ).agg({\"item_price\": [\"mean\"]})\n",
        "group.columns = [\"item_avg_item_price\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = matrix.merge( group, on = [\"item_id\"], how = \"left\" )\n",
        "matrix[\"item_avg_item_price\"] = matrix.item_avg_item_price.astype(np.float16)\n",
        "\n",
        "\n",
        "group = train.groupby( [\"date_block_num\",\"item_id\"] ).agg( {\"item_price\": [\"mean\"]} )\n",
        "group.columns = [\"date_item_avg_item_price\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = matrix.merge(group, on = [\"date_block_num\",\"item_id\"], how = \"left\")\n",
        "matrix[\"date_item_avg_item_price\"] = matrix.date_item_avg_item_price.astype(np.float16)\n",
        "lags = [1, 2, 3]\n",
        "matrix = lag_feature( matrix, lags, [\"date_item_avg_item_price\"] )\n",
        "for i in lags:\n",
        "    matrix[\"delta_price_lag_\" + str(i) ] = (matrix[\"date_item_avg_item_price_lag_\" + str(i)]- matrix[\"item_avg_item_price\"] )/ matrix[\"item_avg_item_price\"]\n",
        "\n",
        "def select_trends(row) :\n",
        "    for i in lags:\n",
        "        if row[\"delta_price_lag_\" + str(i)]:\n",
        "            return row[\"delta_price_lag_\" + str(i)]\n",
        "    return 0\n",
        "\n",
        "matrix[\"delta_price_lag\"] = matrix.apply(select_trends, axis = 1)\n",
        "matrix[\"delta_price_lag\"] = matrix.delta_price_lag.astype( np.float16 )\n",
        "matrix[\"delta_price_lag\"].fillna( 0 ,inplace = True)\n",
        "\n",
        "features_to_drop = [\"item_avg_item_price\", \"date_item_avg_item_price\"]\n",
        "for i in lags:\n",
        "    features_to_drop.append(\"date_item_avg_item_price_lag_\" + str(i) )\n",
        "    features_to_drop.append(\"delta_price_lag_\" + str(i) )\n",
        "matrix.drop(features_to_drop, axis = 1, inplace = True)\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKApaESm0YAc",
        "colab_type": "text"
      },
      "source": [
        "* Add total shop revenue per month to matix df. \n",
        "* Add lag values of revenue per month.\n",
        "* Add delta revenue values - how current month revenue relates to global average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kb9VwcU-0YAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "group = train.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"revenue\": [\"sum\"] })\n",
        "group.columns = [\"date_shop_revenue\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = matrix.merge( group , on = [\"date_block_num\", \"shop_id\"], how = \"left\" )\n",
        "matrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n",
        "\n",
        "group = group.groupby([\"shop_id\"]).agg({ \"date_block_num\":[\"mean\"] })\n",
        "group.columns = [\"shop_avg_revenue\"]\n",
        "group.reset_index(inplace = True )\n",
        "\n",
        "matrix = matrix.merge( group, on = [\"shop_id\"], how = \"left\" )\n",
        "matrix[\"shop_avg_revenue\"] = matrix.shop_avg_revenue.astype(np.float32)\n",
        "matrix[\"delta_revenue\"] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\n",
        "matrix[\"delta_revenue\"] = matrix[\"delta_revenue\"]. astype(np.float32)\n",
        "\n",
        "matrix = lag_feature(matrix, [1], [\"delta_revenue\"])\n",
        "matrix[\"delta_revenue_lag_1\"] = matrix[\"delta_revenue_lag_1\"].astype(np.float32)\n",
        "matrix.drop( [\"date_shop_revenue\", \"shop_avg_revenue\", \"delta_revenue\"] ,axis = 1, inplace = True)\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb4jr-DB0YAi",
        "colab_type": "text"
      },
      "source": [
        "Add month and number of days in each month to matrix df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "do5Vjx2j0YAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix[\"month\"] = matrix[\"date_block_num\"] % 12\n",
        "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
        "matrix[\"days\"] = matrix[\"month\"].map(days).astype(np.int8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR6QVNL10YAq",
        "colab_type": "text"
      },
      "source": [
        "Add the month of each shop and item first sale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xin9VX4Q0YAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "matrix[\"item_shop_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\",\"shop_id\"])[\"date_block_num\"].transform('min')\n",
        "matrix[\"item_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\"])[\"date_block_num\"].transform('min')\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JrGsIbp0YAw",
        "colab_type": "text"
      },
      "source": [
        "Delete first three months from matrix. They don't have lag values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R4yXPVYE0YAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "matrix = matrix[matrix[\"date_block_num\"] > 3]\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-m-_AXSn0YA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVUx_F970YA7",
        "colab_type": "text"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "I-CWjZE-0YA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import pickle\n",
        "from xgboost import XGBRegressor\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 12, 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1beEBKr40YBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = matrix.copy()\n",
        "del matrix\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tOpyJ5Sz0YBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[data[\"date_block_num\"]==34].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuB11ipK0YBJ",
        "colab_type": "text"
      },
      "source": [
        "Use month 34 as validation for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r6_Q2IB40YBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
        "Y_train = data[data.date_block_num < 33]['item_cnt_month']\n",
        "X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
        "Y_valid = data[data.date_block_num == 33]['item_cnt_month']\n",
        "X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PnuSyyy90YBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = Y_train.clip(0, 20)\n",
        "Y_valid = Y_valid.clip(0, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fHmTz1F80YBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del data\n",
        "gc.collect();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eKlHVOKV0YBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = time.time()\n",
        "\n",
        "model = XGBRegressor(\n",
        "    max_depth=10,\n",
        "    n_estimators=1000,\n",
        "    min_child_weight=0.5, \n",
        "    colsample_bytree=0.8, \n",
        "    subsample=0.8, \n",
        "    eta=0.1,\n",
        "#     tree_method='gpu_hist',\n",
        "    seed=42)\n",
        "\n",
        "model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    eval_metric=\"rmse\", \n",
        "    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
        "    verbose=True, \n",
        "    early_stopping_rounds = 20)\n",
        "\n",
        "time.time() - ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rcGC4r_d0YBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = model.predict(X_valid).clip(0, 20)\n",
        "Y_test = model.predict(X_test).clip(0, 20)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": test.index, \n",
        "    \"item_cnt_month\": Y_test\n",
        "})\n",
        "submission.to_csv('xgb_submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VT6UTHbE0YBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import plot_importance\n",
        "\n",
        "def plot_features(booster, figsize):    \n",
        "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
        "    return plot_importance(booster=booster, ax=ax)\n",
        "\n",
        "plot_features(model, (10,14))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}